{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c4b94c0",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "This notebook contains the code to train and evaluate an ensemble of neural networks on the [WILDS Poverty Map](https://wilds.stanford.edu/datasets/#povertymap) dataset.\n",
    "\n",
    "Python packages used in this notebook\n",
    "- [Pytorch](https://pytorch.org/)\n",
    "- [Pytorch Lightning](https://pytorch-lightning.readthedocs.io/en/latest/)\n",
    "- numpy/pandas/scikit-learn\n",
    "\n",
    "**This notebook assumes that you have access to a Nvidia GPU that supports cuda.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4016e7c",
   "metadata": {},
   "source": [
    "## Read training set\n",
    "\n",
    "All image files are stored as `npz` files in `/datasets/cs255-sp22-a00-public/poverty/anon_images` on datahub, which you can directly read by calling [`numpy.load`](https://numpy.org/doc/stable/reference/generated/numpy.load.html). \n",
    "\n",
    "We have already divided all images into a training set and two test sets. \n",
    "- `train.csv`: the training images.\n",
    "- `random_test_reduct.csv`: the test images, whose countries have all appeared in the trianing set. \n",
    "- `country_test_reduct.csv`: the test images, whose countries have NOT appeared in the training set. \n",
    "\n",
    "Testing on `country_test_reduct.csv` should be a harder task than testing on `random_test_reduct.csv` because the images in different countries are not supposed to be in the same distributions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0d6c047",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>country</th>\n",
       "      <th>wealthpooled</th>\n",
       "      <th>urban</th>\n",
       "      <th>label</th>\n",
       "      <th>nl_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>image14517.npz</td>\n",
       "      <td>6</td>\n",
       "      <td>-1.019361</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.086633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>image7407.npz</td>\n",
       "      <td>6</td>\n",
       "      <td>-1.143002</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.141589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>image390.npz</td>\n",
       "      <td>6</td>\n",
       "      <td>1.056769</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>15.228898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>image7980.npz</td>\n",
       "      <td>6</td>\n",
       "      <td>1.454064</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>11.082343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>image13397.npz</td>\n",
       "      <td>6</td>\n",
       "      <td>1.708446</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>12.646744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19659</th>\n",
       "      <td>image13328.npz</td>\n",
       "      <td>8</td>\n",
       "      <td>0.047057</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.216885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19661</th>\n",
       "      <td>image2309.npz</td>\n",
       "      <td>8</td>\n",
       "      <td>0.244931</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.207048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19662</th>\n",
       "      <td>image16557.npz</td>\n",
       "      <td>8</td>\n",
       "      <td>0.952855</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.202403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19665</th>\n",
       "      <td>image4238.npz</td>\n",
       "      <td>8</td>\n",
       "      <td>1.268232</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0.895127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19668</th>\n",
       "      <td>image7340.npz</td>\n",
       "      <td>8</td>\n",
       "      <td>1.880099</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0.844067</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11365 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             filename  country  wealthpooled  urban  label    nl_mean\n",
       "0      image14517.npz        6     -1.019361  False      0  -0.086633\n",
       "2       image7407.npz        6     -1.143002  False      0  -0.141589\n",
       "3        image390.npz        6      1.056769   True      0  15.228898\n",
       "4       image7980.npz        6      1.454064   True      1  11.082343\n",
       "5      image13397.npz        6      1.708446   True      1  12.646744\n",
       "...               ...      ...           ...    ...    ...        ...\n",
       "19659  image13328.npz        8      0.047057  False      1  -0.216885\n",
       "19661   image2309.npz        8      0.244931  False      1  -0.207048\n",
       "19662  image16557.npz        8      0.952855  False      1  -0.202403\n",
       "19665   image4238.npz        8      1.268232   True      0   0.895127\n",
       "19668   image7340.npz        8      1.880099   True      1   0.844067\n",
       "\n",
       "[11365 rows x 6 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_csv_path = '../../public_tables/train.csv'\n",
    "image_path = '/datasets/cs255-sp22-a00-public/poverty/anon_images'\n",
    "\n",
    "train_csv_df = pd.read_csv(train_csv_path, index_col=0)\n",
    "train_csv_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c54e080",
   "metadata": {},
   "source": [
    "## Define Pytorch Dataloader\n",
    "\n",
    "A dataloader is iterator over a datset that generates a batch of instances with labels in each iteration. \n",
    "\n",
    "Here we defines the Pytorch dataloader using\n",
    "\n",
    "- [`torch.utils.data.Dataset`](https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset)\n",
    "- [`torch.utils.data.DataLoader`](https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset)\n",
    "- [`pytorch_lightning.LightningDataModule`](https://pytorch-lightning.readthedocs.io/en/stable/extensions/datamodules.html)\n",
    "\n",
    "The classes we defined here are:\n",
    "- `WildsDataset`: defines how each image is read from the disk (`__getitem__` function).\n",
    "- `BootstrapDM`: defines train and validation dataloaders (`__init__` function). This is a Pytorch Lightning wrapper over the traditional Pytorch dataloaders. \n",
    "\n",
    "In the `__init__` functions in `BootstrapDM` class, we randomly split the training instances into training instances and validation instances and only train the model on the newly splitted training instances. This is important since bootstrap requries that each model in the ensemble should be trained on slightly different training instances. \n",
    "\n",
    "**Note: the \"bootstrapping\" method used here (randomly split into train and validation sets) is not technitically bootstrapping, since the bootstrapping is to sample the dataset randomly with replacement. Thus, the sampled dataset might have duplicates, while randomly splitting into train and validation sets won't have duplicates.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be9b7221",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pytorch_lightning as pl\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class WildsDataset(Dataset):    \n",
    "    def __init__(self, image_paths, idx_to_class=None, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.idx_to_class = idx_to_class\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "            \n",
    "        image = np.load(self.image_paths[idx])\n",
    "        image = image.f.x\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        if self.idx_to_class:\n",
    "            index = self.image_paths[idx].split('/')[-1]\n",
    "            label = self.idx_to_class[index]\n",
    "        else:\n",
    "            return image\n",
    "            \n",
    "        return image, label\n",
    "\n",
    "class BootstrapDM(pl.LightningDataModule):\n",
    "    def __init__(self, csv_path, image_path, batch_size=200, train_val_split_ratio=0.5):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.csv_path = csv_path\n",
    "        self.image_path = image_path\n",
    "        self.batch_size = batch_size\n",
    "        self.train_val_split_ratio = train_val_split_ratio\n",
    "        \n",
    "        # Read metadata csv for all images\n",
    "        csv_df = pd.read_csv(self.csv_path, index_col=0)\n",
    "        \n",
    "        # Get a bootstrap iteration (get train and valid indices)\n",
    "        csv_rows = csv_df.loc[:, ['filename', 'label']].to_dict(orient='records')\n",
    "        train_indices, valid_indices = train_test_split(range(len(csv_rows)), train_size=self.train_val_split_ratio)\n",
    "        \n",
    "        # Get train and valid image paths\n",
    "        train_image_paths = [os.path.join(self.image_path, csv_rows[index]['filename']) for index in train_indices]\n",
    "        valid_image_paths = [os.path.join(self.image_path, csv_rows[index]['filename']) for index in valid_indices]\n",
    "\n",
    "        image_label = {x['filename']: x['label'] for x in csv_rows}\n",
    "        self.train_dataset = WildsDataset(train_image_paths, image_label)\n",
    "        self.val_dataset = WildsDataset(valid_image_paths, image_label)\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        loader = DataLoader(self.train_dataset, batch_size=self.batch_size)\n",
    "        return loader\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        loader = DataLoader(self.val_dataset, batch_size=self.batch_size)\n",
    "        return loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf43f1df",
   "metadata": {},
   "source": [
    "## Define neural network stucture, loss function and training parameters\n",
    "\n",
    "We chose to use the smallest [ResNet](https://pytorch.org/hub/pytorch_vision_resnet/) (resnet18) implemented in Pytorch as the structure of the neural network. \n",
    "\n",
    "We also defined a Pytorch Lightning wrapper (`baseline_module`) of the network. In `baseline_module`, we defined several hyper-parameters that are related to the training process:\n",
    "- Learning rate `self.lr`: 1e-3.\n",
    "- weight decay (l2 regularization) `self.weight_decay`: 1e-4.\n",
    "- loss function `self.loss`: [cross entropy loss](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html).\n",
    "- optimizer `configure_optimizers`: vanilla [SGD](https://pytorch.org/docs/stable/generated/torch.optim.SGD.html) with momentum=0.9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc0f5519",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "from torchmetrics.functional import accuracy\n",
    "\n",
    "from resnet import *\n",
    "\n",
    "class baseline_module(pl.LightningModule):\n",
    "    def __init__(self, lr=1e-3, weight_decay=1e-4):\n",
    "        super().__init__()\n",
    "        self.model = ResNet18(num_classes=2, num_channels=8)\n",
    "        self.loss = nn.CrossEntropyLoss()\n",
    "        self.lr = lr\n",
    "        self.weight_decay = weight_decay\n",
    "        \n",
    "        self.save_hyperparameters()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.model(x)\n",
    "\n",
    "        return out\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.SGD(self.parameters(), lr=self.lr, weight_decay=self.weight_decay, momentum=0.9)\n",
    "        return {'optimizer': optimizer}\n",
    "\n",
    "    def single_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y = y.long()\n",
    "\n",
    "        y_hat_scores = self(x)\n",
    "        _, y_hat = torch.max(y_hat_scores, 1)\n",
    "\n",
    "        loss = self.loss(y_hat_scores, y)\n",
    "        acc = accuracy(y_hat, y)\n",
    "\n",
    "        return loss, acc\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss, acc = self.single_step(batch, batch_idx)\n",
    "\n",
    "        self.log('tloss', loss, on_epoch=True, on_step=False, logger=True, prog_bar=True)\n",
    "        self.log('tacc', acc, on_epoch=True, on_step=False, logger=True, prog_bar=True)\n",
    "\n",
    "        return loss\n",
    "        \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        loss, acc = self.single_step(batch, batch_idx)\n",
    "\n",
    "        self.log('vloss', loss, on_epoch=True, on_step=False, logger=True, prog_bar=True)\n",
    "        self.log('vacc', acc, on_epoch=True, on_step=False, logger=True, prog_bar=True)\n",
    "\n",
    "        return loss\n",
    " \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        loss, acc = self.single_step(batch, batch_idx)\n",
    "\n",
    "        self.log('test_loss', loss, on_epoch=True, on_step=False, logger=True, prog_bar=True)\n",
    "        self.log('test_acc', acc, on_epoch=True, on_step=False, logger=True, prog_bar=True)\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9165c558",
   "metadata": {},
   "source": [
    "## Training \n",
    "\n",
    "Here we start to train the ensemble of the networks. Important variables in the cell:\n",
    "- `num_epochs`: adjust how many epochs we want the network to be trained.\n",
    "- `num_bootstraps`: adjust how many networks are in the ensembles.\n",
    "- `save_folder`: the path to the directory where the models will be saved. Use `None` to disable model saving. \n",
    "- `models`: the list of the network models in the ensemble.\n",
    "\n",
    "Again, the training code of the network (forward-propagation, backward-propagation, and loss evaluation) are all taken cared by Pytorch Lighting package (`trainer.fit`). Please go to the documents of the Pytorch Lighting package if you want to know details.\n",
    "\n",
    "**Training time**:\n",
    "\n",
    "Use the default hyper-parameters, it is estimated to take around 2 mins for 1 epoch. Thus training 10 networks with 20 epochs takes 2 * 20 * 10 = 400 mins = 6.6 hours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8591f2bc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "from pytorch_lightning.plugins import DDPPlugin\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser = BootstrapDM.add_argparse_args(parser)\n",
    "args = parser.parse_args(\"\")\n",
    "\n",
    "save_folder = \"bootstraps2\"\n",
    "num_epochs = 20\n",
    "num_bootstraps = 10\n",
    "\n",
    "models = []\n",
    "trainers = []\n",
    "for i in range(num_bootstraps):\n",
    "    trainer = pl.Trainer(\n",
    "        gpus=1, accelerator='gpu', max_epochs=num_epochs, precision=16,\n",
    "        strategy=DDPPlugin(find_unused_parameters=False),\n",
    "    )\n",
    "\n",
    "    model = baseline_module()\n",
    "    dm = BootstrapDM(train_csv_path, image_path)\n",
    "    trainer.fit(model, datamodule=dm)\n",
    "    if save_folder:\n",
    "        trainer.save_checkpoint(os.path.join(save_folder, f\"bootstrap{i}.ckpt\"))\n",
    "    \n",
    "    models.append(model)\n",
    "    trainers.append(trainer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f95d18c4",
   "metadata": {},
   "source": [
    "### Or load pre-trained models\n",
    "\n",
    "`load_folder`: the path to the directory where the models will be loaded.\n",
    "\n",
    "### WARNNING: executing this cell will overwrite `models`. If you have unsaved trained `models`, save them first before executing the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee442f5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 models loaded\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "    \n",
    "# load_folder = save_folder\n",
    "load_folder = \"bootstraps\"\n",
    "\n",
    "models = []\n",
    "if load_folder:\n",
    "    model_files = sorted([file for file in os.listdir(load_folder) if file.split('.')[1] == 'ckpt'])\n",
    "    for file in model_files:\n",
    "        models.append(baseline_module.load_from_checkpoint(checkpoint_path=os.path.join(load_folder, file)))\n",
    "    \n",
    "print(f'{len(models)} models loaded')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "592b8a1e",
   "metadata": {},
   "source": [
    "## Testing\n",
    "\n",
    "Here we evaluate our ensemble of trained networks on the test set. Again we need to load the test dataset from the disk. However, this time we used standard `torch.utils.data.Dataset` and `torch.utils.data.DataLoader` (no use of the wrapper `pytorch_lightning.LightningDataModule`) to show you how the test data is loaded.\n",
    "\n",
    "The outputs of the network models are stored in two dicts, both of which have the filename as keys and each value is:\n",
    "- `name_labels_nn`: a list of `num_bootstraps` number of predictions (0 or 1) from each model.\n",
    "- `name_scores_nn`: a list of `num_bootstraps` number of outputs (real value between 0 and 1) for label 1 from each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3305d1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on random test set or the country test set\n",
    "TEST_COUNTRY = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3b4f0e05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "46it [01:17,  1.68s/it]\n"
     ]
    }
   ],
   "source": [
    "import ntpath\n",
    "import collections\n",
    "from tqdm import tqdm\n",
    "\n",
    "if TEST_COUNTRY:\n",
    "    test_csv_path = '../../public_tables/country_test_reduct.csv'\n",
    "else:\n",
    "    test_csv_path = '../../public_tables/random_test_reduct.csv'\n",
    "\n",
    "test_csv_df = pd.read_csv(test_csv_path, index_col=0)\n",
    "test_image_paths = [os.path.join(image_path, row['filename']) for index, row in test_csv_df.iterrows()]\n",
    "    \n",
    "test_batch_size = 100\n",
    "test_dataset = WildsDataset(test_image_paths)\n",
    "test_loader = DataLoader(test_dataset, batch_size=test_batch_size)\n",
    "\n",
    "test_image_names = list(map(lambda x: ntpath.basename(x), test_image_paths))\n",
    "\n",
    "name_labels_nn = collections.defaultdict(list)\n",
    "name_scores_nn = collections.defaultdict(list)\n",
    "for batch_index, batch in tqdm(enumerate(test_loader)):\n",
    "    start_index = batch_index * test_batch_size\n",
    "    \n",
    "    for model in models:\n",
    "        model = model.to('cuda')\n",
    "        batch = batch.to('cuda')\n",
    "\n",
    "        output = model(batch)\n",
    "        logits = output.softmax(dim=1)\n",
    "        scores = logits[:, 1]\n",
    "        preds = logits.argmax(dim=1)\n",
    "\n",
    "        for pred_index, pred in enumerate(preds):\n",
    "            name_labels_nn[test_image_names[start_index + pred_index]].append(pred.item())\n",
    "            \n",
    "        for score_index, score in enumerate(scores):\n",
    "            name_scores_nn[test_image_names[start_index + score_index]].append(score.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421aae71",
   "metadata": {},
   "source": [
    "### To predict or to abstain\n",
    "\n",
    "Here we used the outputs from the ensemble of the models to decide the final labels of the test set. The strategy is that we should abstain (do not predict) if we don't have enough confidence of the prediction. \n",
    "- We take the average of either the scores or the labels from the network models in the ensemble as the final score of predicting label 1.\n",
    "- If the score is above `threshold` or below 1 - `threshold`, then we can predict with confidence that the label should be positive (predict 1) or negative (predict -1). \n",
    "- However, if the score is between `threshold` and 1 - `threshold`, then we should abstain (predict 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "10f14094",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>urban</th>\n",
       "      <th>pred_with_abstention</th>\n",
       "      <th>pred_wo_abstention</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>image13747.npz</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>image14972.npz</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>image16964.npz</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>image6808.npz</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>image4311.npz</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4511</th>\n",
       "      <td>image10993.npz</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4512</th>\n",
       "      <td>image3709.npz</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4513</th>\n",
       "      <td>image11650.npz</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4514</th>\n",
       "      <td>image13495.npz</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4515</th>\n",
       "      <td>image6657.npz</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4516 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            filename  urban  pred_with_abstention  pred_wo_abstention\n",
       "0     image13747.npz      0                    -1                  -1\n",
       "1     image14972.npz      1                    -1                  -1\n",
       "2     image16964.npz      1                     1                   1\n",
       "3      image6808.npz      1                     0                  -1\n",
       "4      image4311.npz      1                     0                  -1\n",
       "...              ...    ...                   ...                 ...\n",
       "4511  image10993.npz      0                     0                   1\n",
       "4512   image3709.npz      1                     0                   1\n",
       "4513  image11650.npz      1                     0                  -1\n",
       "4514  image13495.npz      1                     0                   1\n",
       "4515   image6657.npz      0                     0                   1\n",
       "\n",
       "[4516 rows x 4 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_preds(threshold=0.6, use_score=True):\n",
    "    name_preds = []\n",
    "    for index, row in test_csv_df.iterrows():\n",
    "        filename = row['filename']\n",
    "        if use_score:\n",
    "            mean_output = np.mean(name_scores_nn[filename])\n",
    "        else:\n",
    "            mean_output = np.mean(name_labels_nn[filename])\n",
    "\n",
    "        if mean_output >= threshold:\n",
    "            pred = 1\n",
    "        elif mean_output <= 1 - threshold:\n",
    "            pred = -1\n",
    "        else:\n",
    "            pred = 0\n",
    "        \n",
    "        pred_accu = 1 if mean_output > 0.5 else -1\n",
    "        name_preds.append([filename, pred, pred_accu])\n",
    "    preds_df = pd.DataFrame(name_preds, columns=['filename', 'pred_with_abstention', 'pred_wo_abstention'])\n",
    "    \n",
    "    return preds_df\n",
    "        \n",
    "preds_df = get_preds()\n",
    "outputs_df = test_csv_df[['filename', 'urban']].merge(preds_df, on='filename')\n",
    "outputs_df = outputs_df.astype({'urban': int})\n",
    "outputs_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104e7d7b",
   "metadata": {},
   "source": [
    "## Upload your predictions\n",
    "\n",
    "You can directly upload the saved csv file to gradescope to see how your models perform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1fdd5291",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_df.to_csv('results_country.csv' if TEST_COUNTRY else 'results.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a173e5",
   "metadata": {},
   "source": [
    "### Statistics of the pretrained models\n",
    "\n",
    "Using the average scores of neural network ensembles, we get these statistics for `random_test_reduct.csv`:\n",
    "\n",
    "- Classification accuracy: 0.57\n",
    "- Assymetric loss using threshold = 0.7 and alpha = 2: -0.0184\n",
    "- Score distribution:\n",
    "    ![image](score_distribution.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
